import streamlit as st
import pandas as pd
import numpy as np
import torch
import timesfm
import matplotlib.pyplot as plt
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# Page configuration
st.set_page_config(
    page_title="TimesFM Forecasting Tool",
    page_icon="üìà",
    layout="wide"
)

# Initialize TimesFM model
@st.cache_resource
def load_model():
    torch.set_float32_matmul_precision("high")
    LOCAL_MODEL_PATH = "./timesfm_model"
    
    try:
        model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(LOCAL_MODEL_PATH)
        st.success(f"‚úì Model loaded from local path: {LOCAL_MODEL_PATH}")
    except Exception as e:
        st.warning(f"Failed to load from local path, trying HuggingFace...")
        model = timesfm.TimesFM_2p5_200M_torch.from_pretrained("google/timesfm-2.5-200m-pytorch")
        st.success("‚úì Model loaded from HuggingFace")
    
    model.compile(
        timesfm.ForecastConfig(
            max_context=1024,
            max_horizon=256,
            normalize_inputs=True,
            use_continuous_quantile_head=True,
            force_flip_invariance=True,
            infer_is_positive=True,
            fix_quantile_crossing=True,
        )
    )
    return model

def initialize_chat_model(api_key, temperature=0.7):
    """Initialize OpenAI chat model with LangChain"""
    try:
        llm = ChatOpenAI(
            temperature=temperature,
            model_name="gpt-4o-mini",  # or "gpt-3.5-turbo" for lower cost
            openai_api_key=api_key,
            streaming=True
        )
        return llm
    except Exception as e:
        st.error(f"Error initializing OpenAI: {str(e)}")
        return None

def create_forecast_context(forecast_data, summary):
    """Create a detailed context about the forecast for the LLM"""
    context = f"""
You are a helpful data analyst assistant specializing in time series forecasting. You have access to forecast data generated by Google's TimesFM model.

FORECAST DATA SUMMARY:
====================

Historical Statistics:
- Number of data points: {summary['historical_stats']['count']}
- Mean: {summary['historical_stats']['mean']:,.2f}
- Standard Deviation: {summary['historical_stats']['std']:,.2f}
- Minimum: {summary['historical_stats']['min']:,.2f}
- Maximum: {summary['historical_stats']['max']:,.2f}
- Total: {summary['historical_stats']['total']:,.2f}

Forecast Statistics:
- Number of forecast periods: {summary['forecast_stats']['count']}
- Mean: {summary['forecast_stats']['mean']:,.2f}
- Standard Deviation: {summary['forecast_stats']['std']:,.2f}
- Minimum: {summary['forecast_stats']['min']:,.2f}
- Maximum: {summary['forecast_stats']['max']:,.2f}
- Total: {summary['forecast_stats']['total']:,.2f}

Trend Analysis:
- Direction: {summary['trend']['direction']}
- Change from historical average: {summary['trend']['change_percent']:.2f}%

Confidence Intervals:
- 80% Prediction Interval: [{summary['confidence_intervals']['80_percent']['lower']:,.2f}, {summary['confidence_intervals']['80_percent']['upper']:,.2f}]
- 50% Prediction Interval: [{summary['confidence_intervals']['50_percent']['lower']:,.2f}, {summary['confidence_intervals']['50_percent']['upper']:,.2f}]

Detailed Forecast Values:
"""
    
    for i, period in enumerate(forecast_data['periods']):
        context += f"\n- {period}: {forecast_data['point_forecast'][i]:,.2f}"
        context += f" (Range: {forecast_data['quantiles']['q10'][i]:,.2f} to {forecast_data['quantiles']['q90'][i]:,.2f})"
    
    context += """

INSTRUCTIONS:
- Answer questions about the forecast data naturally and conversationally
- Use the specific numbers provided when relevant
- Explain trends, patterns, and insights
- When discussing confidence intervals, explain what they mean in practical terms
- Be concise but informative
- If asked about specific periods, provide exact values
- Help users understand the business implications of the forecast
- Format numbers with appropriate precision (usually 2 decimal places)
- Use markdown formatting for better readability when appropriate
"""
    
    return context

def load_and_prepare_data(df, target_column, date_column, aggregation, time_period):
    """Prepare time series data from dataframe"""
    # Make a copy to avoid modifying original
    df = df.copy()
    
    # Convert date column to datetime with multiple format attempts
    date_formats = [
        '%d-%m-%Y',  # 01-01-1985
        '%m-%d-%Y',  # 01-01-1985 (alternative interpretation)
        '%Y-%m-%d',  # 1985-01-01
        '%m/%d/%Y %H:%M',  # 2/24/2003 0:00
        '%d/%m/%Y %H:%M',  # 24/2/2003 0:00
        '%Y-%m-%d %H:%M:%S',
        '%Y-%m-%d %H:%M',
        '%d-%m-%Y %H:%M:%S',
        '%d-%m-%Y %H:%M',
        '%m/%d/%Y',
        '%d/%m/%Y',
        '%Y/%m/%d',
        '%d.%m.%Y',  # 01.01.1985
        '%Y.%m.%d',  # 1985.01.01
    ]
    
    parsed_successfully = False
    successful_format = None
    
    for fmt in date_formats:
        try:
            test_parse = pd.to_datetime(df[date_column], format=fmt, errors='coerce')
            # Check if at least some dates were parsed
            if test_parse.notna().sum() > 0:
                df[date_column] = test_parse
                parsed_successfully = True
                successful_format = fmt
                break
        except:
            continue
    
    # If no format worked, try automatic parsing
    if not parsed_successfully:
        try:
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce', infer_datetime_format=True)
            if df[date_column].notna().sum() > 0:
                parsed_successfully = True
                successful_format = "auto-detected"
        except:
            pass
    
    if not parsed_successfully:
        # Show first few non-null values to help debug
        sample_values = df[date_column].dropna().head(5).tolist()
        raise ValueError(f"Could not parse dates in column '{date_column}'. Sample values: {sample_values}")
    
    # Remove rows with invalid dates or missing target values
    initial_count = len(df)
    df = df.dropna(subset=[date_column, target_column])
    removed_count = initial_count - len(df)
    
    if len(df) == 0:
        raise ValueError(f"No valid data after removing {removed_count} rows with invalid dates or missing target values.")
    
    # Sort by date
    df = df.sort_values(date_column)
    
    # Create period column based on time_period
    if time_period == "Day":
        df['period'] = df[date_column].dt.strftime('%d-%b-%Y')
        period_format = "day"
    elif time_period == "Week":
        df['period'] = df[date_column].dt.strftime('Week %U, %Y')
        period_format = "week"
    elif time_period == "Month":
        df['period'] = df[date_column].dt.strftime('%B %Y')
        period_format = "month"
    elif time_period == "Year":
        df['period'] = df[date_column].dt.year.astype(str)
        period_format = "year"
    else:
        df['period'] = df[date_column].dt.strftime('%B %Y')
        period_format = "month"
    
    # Group by period and aggregate
    if aggregation == "Sum":
        grouped = df.groupby('period')[target_column].sum()
    elif aggregation == "Mean":
        grouped = df.groupby('period')[target_column].mean()
    elif aggregation == "Median":
        grouped = df.groupby('period')[target_column].median()
    elif aggregation == "Count":
        grouped = df.groupby('period')[target_column].count()
    else:
        grouped = df.groupby('period')[target_column].sum()
    
    periods = grouped.index.tolist()
    values = grouped.values.tolist()
    
    return periods, values, period_format

def generate_forecast_labels(last_period, horizon, period_format):
    """Generate forecast period labels"""
    forecast_labels = []
    
    if period_format == "month":
        try:
            last_date = pd.to_datetime(last_period, format='%B %Y')
            for i in range(1, horizon + 1):
                next_date = last_date + pd.DateOffset(months=i)
                forecast_labels.append(next_date.strftime('%B %Y'))
        except:
            forecast_labels = [f"Forecast {i+1}" for i in range(horizon)]
    elif period_format == "day":
        try:
            last_date = pd.to_datetime(last_period, format='%d-%b-%Y')
            for i in range(1, horizon + 1):
                next_date = last_date + pd.Timedelta(days=i)
                forecast_labels.append(next_date.strftime('%d-%b-%Y'))
        except:
            forecast_labels = [f"Forecast {i+1}" for i in range(horizon)]
    elif period_format == "year":
        try:
            last_year = int(last_period)
            forecast_labels = [str(last_year + i) for i in range(1, horizon + 1)]
        except:
            forecast_labels = [f"Forecast {i+1}" for i in range(horizon)]
    else:
        forecast_labels = [f"Forecast {i+1}" for i in range(horizon)]
    
    return forecast_labels

# Main UI
st.title("üìà TimesFM Forecasting Tool with AI Chat")
st.markdown("Upload your data and generate time series forecasts using Google's TimesFM model")

# Load model
with st.spinner("Loading TimesFM model..."):
    model = load_model()

# Sidebar for controls
st.sidebar.header("‚öôÔ∏è Configuration")

# OpenAI API Key input
with st.sidebar.expander("üîë OpenAI API Key", expanded=True):
    api_key = st.text_input(
        "Enter your OpenAI API Key:",
        type="password",
        help="Your API key is not stored and only used for this session"
    )
    
    temperature = st.slider(
        "Chat Temperature",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="Higher values make responses more creative, lower values more focused"
    )
    
    if api_key:
        st.success("‚úì API Key provided")
    else:
        st.warning("‚ö†Ô∏è Please enter your OpenAI API key to use the chat feature")

st.sidebar.header("‚öôÔ∏è Forecast Configuration")

# Data input method
input_method = st.sidebar.radio("Data Input Method", ["Upload CSV", "Paste Text Data"])

df = None

if input_method == "Upload CSV":
    uploaded_file = st.sidebar.file_uploader("Upload CSV File", type=['csv'])
    if uploaded_file:
        # Try different encodings
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'utf-16']
        df = None
        
        for encoding in encodings:
            try:
                uploaded_file.seek(0)  # Reset file pointer
                df = pd.read_csv(uploaded_file, encoding=encoding, on_bad_lines='skip')
                st.sidebar.success(f"‚úì Loaded {len(df)} rows (encoding: {encoding})")
                break
            except (UnicodeDecodeError, Exception) as e:
                continue
        
        if df is None:
            st.sidebar.error("‚ùå Could not read file. Please check the file encoding.")
else:
    text_data = st.sidebar.text_area("Paste CSV Data (with headers)", height=200)
    if text_data:
        from io import StringIO
        df = pd.read_csv(StringIO(text_data))
        st.sidebar.success(f"‚úì Loaded {len(df)} rows")

# Main content area
if df is not None:
    # Show data preview
    with st.expander("üìä Data Preview", expanded=True):
        st.dataframe(df.head(10), use_container_width=True)
        st.info(f"Total rows: {len(df)} | Columns: {len(df.columns)}")
    
    # Configuration
    col1, col2 = st.sidebar.columns(2)
    
    # Get numeric and date columns
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    all_cols = df.columns.tolist()
    
    with col1:
        date_column = st.selectbox("Date Column", all_cols)
    
    with col2:
        target_column = st.selectbox("Target Column", numeric_cols)
    
    col3, col4 = st.sidebar.columns(2)
    
    with col3:
        time_period = st.selectbox("Time Period", ["Day", "Week", "Month", "Year"])
    
    with col4:
        aggregation = st.selectbox("Aggregation", ["Sum", "Mean", "Median", "Count"])
    
    horizon = st.sidebar.slider("Forecast Horizon", min_value=1, max_value=24, value=6)
    
    # Forecast button
    if st.sidebar.button("üöÄ Generate Forecast", type="primary", use_container_width=True):
        with st.spinner("Generating forecast..."):
            try:
                # Prepare data
                periods, values, period_format = load_and_prepare_data(
                    df.copy(), target_column, date_column, aggregation, time_period
                )
                
                if len(values) < 3:
                    st.error(f"Not enough data points after aggregation. Got {len(values)}, need at least 3")
                else:
                    # Generate forecast
                    historical_array = np.array(values, dtype=np.float32)
                    point_forecast, quantile_forecast = model.forecast(
                        horizon=horizon,
                        inputs=[historical_array],
                    )
                    
                    forecast_values = point_forecast[0]
                    quantiles = quantile_forecast[0]
                    
                    # Generate labels
                    forecast_labels = generate_forecast_labels(periods[-1], horizon, period_format)
                    
                    # Convert to native types
                    forecast_values_list = [float(x) for x in forecast_values]
                    
                    # Store in session state
                    st.session_state['forecast_data'] = {
                        'periods': forecast_labels,
                        'point_forecast': forecast_values_list,
                        'quantiles': {
                            'q10': [float(x) for x in quantiles[:, 1]],
                            'q25': [float(x) for x in quantiles[:, 3]],
                            'q50': [float(x) for x in quantiles[:, 5]],
                            'q75': [float(x) for x in quantiles[:, 7]],
                            'q90': [float(x) for x in quantiles[:, 9]]
                        },
                        'horizon': horizon
                    }
                    
                    st.session_state['summary'] = {
                        'historical_stats': {
                            'count': len(values),
                            'mean': float(np.mean(values)),
                            'std': float(np.std(values)),
                            'min': float(np.min(values)),
                            'max': float(np.max(values)),
                            'total': float(np.sum(values))
                        },
                        'forecast_stats': {
                            'count': len(forecast_values),
                            'mean': float(np.mean(forecast_values)),
                            'std': float(np.std(forecast_values)),
                            'min': float(np.min(forecast_values)),
                            'max': float(np.max(forecast_values)),
                            'total': float(np.sum(forecast_values))
                        },
                        'trend': {
                            'direction': 'increasing' if np.mean(forecast_values) > np.mean(values) else 'decreasing',
                            'change_percent': ((np.mean(forecast_values) - np.mean(values)) / np.mean(values) * 100) if np.mean(values) != 0 else 0
                        },
                        'confidence_intervals': {
                            '80_percent': {
                                'lower': float(np.mean(quantiles[:, 1])),
                                'upper': float(np.mean(quantiles[:, 9]))
                            },
                            '50_percent': {
                                'lower': float(np.mean(quantiles[:, 3])),
                                'upper': float(np.mean(quantiles[:, 7]))
                            }
                        }
                    }
                    
                    st.session_state['periods'] = periods
                    st.session_state['values'] = values
                    st.session_state['forecast_labels'] = forecast_labels
                    st.session_state['quantiles'] = quantiles
                    st.session_state['target_column'] = target_column
                    
                    # Initialize chat history
                    if 'chat_history' not in st.session_state:
                        st.session_state['chat_history'] = []
                    
                    st.success("‚úì Forecast generated successfully!")
                    st.rerun()
                    
            except Exception as e:
                st.error(f"Error generating forecast: {str(e)}")
    
    # Display results if forecast exists
    if 'forecast_data' in st.session_state:
        st.markdown("---")
        st.header("üìä Forecast Results")
        
        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Historical Mean",
                f"{st.session_state['summary']['historical_stats']['mean']:,.2f}"
            )
        
        with col2:
            st.metric(
                "Forecast Mean",
                f"{st.session_state['summary']['forecast_stats']['mean']:,.2f}",
                delta=f"{st.session_state['summary']['trend']['change_percent']:.2f}%"
            )
        
        with col3:
            st.metric(
                "Trend",
                st.session_state['summary']['trend']['direction'].title()
            )
        
        with col4:
            st.metric(
                "Forecast Periods",
                st.session_state['forecast_data']['horizon']
            )
        
        # Visualization
        st.subheader("üìà Forecast Visualization")
        
        fig, ax = plt.subplots(figsize=(14, 6))
        
        periods = st.session_state['periods']
        values = st.session_state['values']
        forecast_labels = st.session_state['forecast_labels']
        forecast_values = st.session_state['forecast_data']['point_forecast']
        quantiles = st.session_state['quantiles']
        
        # Create x-axis
        total_points = len(values) + len(forecast_values)
        all_x = list(range(total_points))
        hist_x = all_x[:len(values)]
        forecast_x = all_x[len(values)-1:]
        
        # Plot
        ax.plot(hist_x, values, label="Historical Data", color="#3498db", 
                linewidth=2, marker='o', markersize=4)
        
        forecast_with_connection = [values[-1]] + forecast_values
        ax.plot(forecast_x, forecast_with_connection, label="Forecast", 
                color="#2ecc71", linewidth=2, marker='s', markersize=4)
        
        # Confidence intervals
        quantiles_with_connection = np.vstack([[values[-1]] * quantiles.shape[1], quantiles])
        
        ax.fill_between(forecast_x, quantiles_with_connection[:, 1], 
                        quantiles_with_connection[:, 9], alpha=0.2, 
                        color='#2ecc71', label='80% Prediction Interval')
        
        ax.fill_between(forecast_x, quantiles_with_connection[:, 3], 
                        quantiles_with_connection[:, 7], alpha=0.3, 
                        color='#2ecc71', label='50% Prediction Interval')
        
        # Labels
        all_labels = periods + forecast_labels
        step = max(1, len(all_labels) // 12)
        tick_positions = list(range(0, len(all_labels), step))
        tick_labels = [all_labels[i] for i in tick_positions]
        
        ax.set_xticks(tick_positions)
        ax.set_xticklabels(tick_labels, rotation=45, ha='right')
        ax.legend(loc='best')
        ax.set_title(f"TimesFM Forecast: {st.session_state['target_column']}", 
                     fontsize=14, fontweight='bold')
        ax.set_xlabel("Period")
        ax.set_ylabel(st.session_state['target_column'])
        ax.grid(True, linestyle='--', alpha=0.6)
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # Forecast table
        st.subheader("üìã Forecast Values")
        
        forecast_df = pd.DataFrame({
            'Period': st.session_state['forecast_data']['periods'],
            'Forecast': st.session_state['forecast_data']['point_forecast'],
            'Lower (10%)': st.session_state['forecast_data']['quantiles']['q10'],
            'Lower (25%)': st.session_state['forecast_data']['quantiles']['q25'],
            'Median': st.session_state['forecast_data']['quantiles']['q50'],
            'Upper (75%)': st.session_state['forecast_data']['quantiles']['q75'],
            'Upper (90%)': st.session_state['forecast_data']['quantiles']['q90']
        })
        
        st.dataframe(forecast_df.style.format({
            'Forecast': '{:,.2f}',
            'Lower (10%)': '{:,.2f}',
            'Lower (25%)': '{:,.2f}',
            'Median': '{:,.2f}',
            'Upper (75%)': '{:,.2f}',
            'Upper (90%)': '{:,.2f}'
        }), use_container_width=True)
        
        # AI Chat Interface
        st.markdown("---")
        st.subheader("üí¨ AI-Powered Forecast Analysis")
        
        if not api_key:
            st.warning("‚ö†Ô∏è Please enter your OpenAI API key in the sidebar to use the AI chat feature")
        else:
            # Initialize chat model
            if 'chat_model' not in st.session_state or st.session_state.get('current_api_key') != api_key:
                st.session_state['chat_model'] = initialize_chat_model(api_key, temperature)
                st.session_state['current_api_key'] = api_key
                st.session_state['forecast_context'] = create_forecast_context(
                    st.session_state['forecast_data'],
                    st.session_state['summary']
                )
            
            if st.session_state.get('chat_model'):
                # Initialize chat history
                if 'chat_history' not in st.session_state:
                    st.session_state['chat_history'] = []
                
                # Display chat history
                for message in st.session_state['chat_history']:
                    if message['role'] == 'user':
                        with st.chat_message("user"):
                            st.write(message['content'])
                    else:
                        with st.chat_message("assistant"):
                            st.write(message['content'])
                
                # Chat input
                user_query = st.chat_input("Ask me anything about your forecast...")
                
                if user_query:
                    # Add user message to chat
                    st.session_state['chat_history'].append({
                        'role': 'user',
                        'content': user_query
                    })
                    
                    with st.chat_message("user"):
                        st.write(user_query)
                    
                    # Generate response
                    with st.chat_message("assistant"):
                        with st.spinner("Thinking..."):
                            try:
                                # Create messages for the API call
                                messages = [
                                    SystemMessage(content=st.session_state['forecast_context'])
                                ]
                                
                                # Add chat history (last 10 messages to avoid token limits)
                                for msg in st.session_state['chat_history'][-10:]:
                                    if msg['role'] == 'user':
                                        messages.append(HumanMessage(content=msg['content']))
                                    else:
                                        messages.append(AIMessage(content=msg['content']))
                                
                                # Get response
                                response = st.session_state['chat_model'].invoke(messages)
                                response_content = response.content
                                
                                st.write(response_content)
                                
                                # Add assistant response to chat history
                                st.session_state['chat_history'].append({
                                    'role': 'assistant',
                                    'content': response_content
                                })
                                
                            except Exception as e:
                                st.error(f"Error generating response: {str(e)}")
                
                # Clear chat button
                col1, col2 = st.columns([6, 1])
                with col2:
                    if st.button("üóëÔ∏è Clear Chat"):
                        st.session_state['chat_history'] = []
                        st.rerun()
                
                # Suggested questions
                with st.expander("üí° Suggested Questions"):
                    st.markdown("""
                    Try asking:
                    - "What are the key insights from this forecast?"
                    - "Which period has the highest predicted value and why might that be?"
                    - "How confident should I be in these predictions?"
                    - "What does the trend suggest for business planning?"
                    - "Compare the forecast with historical performance"
                    - "What risks should I consider based on the confidence intervals?"
                    - "Explain the forecast in simple terms for non-technical stakeholders"
                    """)

else:
    # Welcome screen
    st.info("üëà Please upload a CSV file or paste your data to get started")
    
    st.markdown("""
    ### How to use this tool:
    
    1. **API Key**: Enter your OpenAI API key in the sidebar
    2. **Upload Data**: Choose to upload a CSV file or paste text data
    3. **Configure**: Select your date column, target column, and forecast settings
    4. **Generate**: Click the "Generate Forecast" button
    5. **Analyze**: View the forecast visualization and chat with AI about your results
    
    ### Supported Features:
    
    - ‚úÖ Multiple time periods (Day, Week, Month, Year)
    - ‚úÖ Various aggregation methods (Sum, Mean, Median, Count)
    - ‚úÖ Customizable forecast horizon (1-24 periods)
    - ‚úÖ Confidence intervals (50% and 80%)
    - ‚úÖ **AI-powered natural language analysis with OpenAI**
    - ‚úÖ **Conversational insights and explanations**
    
    ### New AI Chat Features:
    
    - ü§ñ Natural language interaction with your forecast data
    - üìä Intelligent analysis and insights
    - üí° Context-aware responses based on your specific forecast
    - üîÑ Conversational memory for follow-up questions
    """)

# Footer
st.sidebar.markdown("---")
st.sidebar.markdown("**TimesFM 2.5 200M PyTorch**")
st.sidebar.caption("Powered by Google Research")
st.sidebar.caption("AI Chat powered by OpenAI + LangChain")